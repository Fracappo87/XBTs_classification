{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decisions Trees - Feature Importance\n",
    "\n",
    "This notebook demonstrates evaluating the relative importance of difference features that we might use as input to our machine learning models. We will use the scikit-learn `permutation_feature_importance` algorithm to determine which are the most important input features.\n",
    "\n",
    "This algorithm works by adding random to noise to inpout features and testing how much performance is degraded by the degradation of input data. This is done for each input variable in turn. If a variable is important, when it is degraded by random noise, there will be a significant degradation in classification accuracy. Conversely, if a feature is nopt important to the classification algorithm, then the added noise will not result in much change to the classification accuracy in the resulting trained model. \n",
    "\n",
    "https://scikit-learn.org/stable/modules/permutation_importance.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import functools\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 32}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.pyplot.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import sklearn.tree\n",
    "import sklearn.metrics\n",
    "import sklearn.inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_repo_dir = pathlib.Path().absolute().parent\n",
    "sys.path = [os.path.join(root_repo_dir)] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xbt.dataset\n",
    "from xbt.dataset import XbtDataset, UNKNOWN_STR, cat_output_formatter, check_value_found\n",
    "from xbt.imeta import imeta_classification, XBT_MAX_DEPTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some site specific parameters for the notebook\n",
    "try:\n",
    "    environment = os.environ['XBT_ENV_NAME']\n",
    "except KeyError:\n",
    "    environment = 'pangeo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_dirs = {\n",
    "    'MO_scitools': '/data/users/shaddad/xbt-data/',\n",
    "    'pangeo': '/data/misc/xbt-data/',\n",
    "}\n",
    "env_date_ranges = {\n",
    "    'MO_scitools': (1966,2015),\n",
    "    'pangeo': (1966,2015)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some dataset specific parameters\n",
    "root_data_dir = root_data_dirs[environment]\n",
    "year_range = env_date_ranges[environment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/users/shaddad/xbt-data/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_metric_names = ['f1_weighted','precision_weighted','recall_weighted']\n",
    "input_feature_names = ['country','max_depth', 'year', 'lat', 'lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_name = 'csv_with_imeta'\n",
    "exp_out_dir_name = 'experiment_outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'nb_single_decisionTree_country'\n",
    "classifier_class = sklearn.tree.DecisionTreeClassifier\n",
    "classifier_name = 'decision_tree'\n",
    "suffix='countryAndLatLon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_opts = {'max_depth': 20,\n",
    "                   'min_samples_leaf': 1,\n",
    "                   'criterion': 'gini'\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbt_input_dir = os.path.join(root_data_dir, input_dir_name)\n",
    "xbt_output_dir = os.path.join(root_data_dir, exp_out_dir_name, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputting to /data/users/shaddad/xbt-data/experiment_outputs/nb_single_decisionTree_country\n"
     ]
    }
   ],
   "source": [
    "# create the output for this experiment if it doesn't exist\n",
    "if not os.path.isdir(xbt_output_dir):\n",
    "    os.makedirs(xbt_output_dir)\n",
    "print(f'outputting to {xbt_output_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fname_template = 'xbt_output_{exp_name}_{subset}.csv'\n",
    "result_fname_template = 'xbt_metrics_{classifier}_{suffix}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.7 s, sys: 15.8 s, total: 1min 11s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xbt_full_dataset = XbtDataset(xbt_input_dir, year_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "We are only testing on the labelled data, to be able to evluate performance. The XbtDataset class has filtered out some bad data including profiles with maximum depths less that 0.0 or greater than 2000.0. There were also some profiles with bad date entries, which have been excluded for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 285 ms, sys: 51.3 ms, total: 337 ms\n",
      "Wall time: 334 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xbt_labelled = xbt_full_dataset.filter_obs({'labelled': 'labelled'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbt_unlabelled = xbt_full_dataset.filter_obs({'labelled': 'unlabelled'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = xbt_labelled.get_ml_dataset(return_data = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = xbt_labelled.filter_features(['instrument','model','manufacturer']).encode_target(return_data = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.6 ms, sys: 2.62 ms, total: 25.2 ms\n",
      "Wall time: 22.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unseen_cruise_numbers = xbt_labelled.sample_feature_values('cruise_number', fraction=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xbt_unseen = xbt_labelled.filter_obs({'cruise_number': unseen_cruise_numbers}, mode='include', check_type='in_filter_set')\n",
    "xbt_working = xbt_labelled.filter_obs({'cruise_number': unseen_cruise_numbers}, mode='exclude', check_type='in_filter_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imeta_classes = xbt_labelled.xbt_df.apply(imeta_classification, axis=1)\n",
    "imeta_model = imeta_classes.apply(lambda t1: t1[0])\n",
    "imeta_manufacturer = imeta_classes.apply(lambda t1: t1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imeta_instrument = imeta_classes.apply(lambda t1: f'XBT: {t1[0]} ({t1[1]})') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are currently training and evaulating separately for model and manufacturer. We will also need to train and evaulate together as this is ultimately what is wanted (a combined probe model and manufacturer field).\n",
    "\n",
    "We are using the default 80/20 split in scikit-learn for now. Further work will need to do proper cross validation where several different splits are randomly selected to verify our results are not an artifact of the randomly chosen split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xbt_train_all, xbt_test_all = xbt_working.train_test_split(refresh=True, features=['instrument', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all, _, _, _, feature_names = xbt_train_all.filter_features(input_feature_names).get_ml_dataset()\n",
    "X_test_all = xbt_test_all.filter_features(input_feature_names).get_ml_dataset()[0]\n",
    "X_unseen_all = xbt_unseen.filter_features(input_feature_names).get_ml_dataset()[0]\n",
    "y_instr_train_all = xbt_train_all.filter_features(['instrument']).get_ml_dataset()[0]\n",
    "y_instr_test_all = xbt_test_all.filter_features(['instrument']).get_ml_dataset()[0]\n",
    "y_instr_unseen_all = xbt_unseen.filter_features(['instrument']).get_ml_dataset()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier\n",
    "\n",
    "We are using the scikit-learn classifier as the closest analogue to the structure of the iMeta algorithm. This tree can have many more nodes and leaves than iMeta though. it is quick to train and evaluate so it is a useful starting point for setting up the ML processing pipelines, as all the scikit-learn classifiers have a common interface. \n",
    "\n",
    "For the model and manufacturer, we train a Decision ree Classifier, then use it to predict values for the train and test sets. We then calculate the accuracy metrics for each for the whole dataset. \n",
    "\n",
    "I am using precision, recall and F1 as fairly standard ML metrics of accuracy. Recall is what has been used in the two previous papers (Palmer et. al, Leahy and Llopis et al) so that is the focus. Support is a useful to see what proportion of the profiles in the dataset belong to each of the different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_per_class_all = {}\n",
    "metrics_avg_all = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt_instr1 = classifier_class(**classifier_opts)\n",
    "clf_dt_instr1.fit(X_train_all,y_instr_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "importances_dict = sklearn.inspection.permutation_importance(\n",
    "    clf_dt_instr1,\n",
    "    X_test_all,\n",
    "    y_instr_test_all,\n",
    "    n_repeats=10,\n",
    "    random_state=0,\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = pandas.DataFrame({\n",
    "    'features': feature_names,\n",
    "    'importances_mean': importances_dict['importances_mean'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = matplotlib.pyplot.figure(figsize=(16,10))\n",
    "ax1 = fig1.add_subplot(1,1,1, title='XBT Feature importance')\n",
    "importance_df[importance_df['importances_mean']>2e-3].plot.bar(x='features', y='importances_mean', ax=ax1)\n",
    "fig1.savefig('/data/users/shaddad/xbt-data/plots/feature_importances_dt.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that maximum depth (derived from the depth profile information) and year of measurement are the most important. We see that the country codes for certain countries are the most important, reflecting the countries that have made the most measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other classification algorithms\n",
    "\n",
    "Lets compare results for other classification algorithms to see how feature importance might differ based on the type of algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_importances_root_dir = '/scratch/shaddad/xbt-data/journal_paper_importance_202104/'\n",
    "batch_importances_file_list = {\n",
    "    'random_forest': 'RandomForest_countryLatLon/xbt_importance_RandomForest_countryLatLon_20210422_1756.csv',\n",
    "    'decision_tree': 'decisionTree_countryLatLon/xbt_importance_decisionTree_countryLatLon_20210422_1756.csv',\n",
    "    'logistic_regression': 'logreg_country/xbt_importance_logreg_country_20210422_1756.csv',\n",
    "    'neural_network': 'mlp_countryLatLon/xbt_importance_mlp_countryLatLon_20210422_1756.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_importances_path_list = {clf_name: os.path.join(batch_importances_root_dir,\n",
    "                                            fn1\n",
    "                                           ) for clf_name, fn1 in batch_importances_file_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_df_list = {clf_name: pandas.read_csv(p1) for clf_name, p1 in batch_importances_path_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_df_list = {clf_name: df1.rename({\n",
    "    'importances_stdev': f'importances_std_{clf_name}',\n",
    "    'importances_mean': f'importances_mean_{clf_name}',\n",
    "},axis='columns') for clf_name, df1 in importances_df_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_importances_df = functools.reduce(lambda x,y: pandas.merge(x,y, on='instrument'), importances_df_list.values()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_batch_importances = matplotlib.pyplot.figure('batch_importances', figsize=(16,10))\n",
    "ax_batch_importances = fig_batch_importances.add_subplot(1,1,1, title='comparison of feature importances for algorithms')\n",
    "batch_importances_df.plot.bar(x='instrument', \n",
    "                              y=[f'importances_mean_{clf_name}' for clf_name in importances_df_list.keys()],\n",
    "                             ax=ax_batch_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experimental-current",
   "language": "python",
   "name": "experimental-current"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
